# AI Assistant Instructions for Python Development Container

## Environment Context
This code is running in a **development container** with:
- Python 3.11+ with comprehensive data science and cybersecurity libraries
- PostgreSQL database with pre-configured connection
- Jupyter Lab for interactive development
- VS Code with Python extensions pre-installed
- Docker environment with volume persistence
- Pre-installed security and analysis tools

## Coding Standards & Conventions

### Python-Specific Naming Conventions
- **Variables**: Use `camelCase` for all variable names
  ```python
  # Correct
  userEmail = "user@example.com"
  apiResponse = requests.get(url)
  connectionString = "postgresql://..."
  
  # Incorrect
  user_email = "user@example.com"
  api_response = requests.get(url)
  ```

- **Methods/Functions**: Use `snake_case` for all method and function names
  ```python
  # Correct
  def process_user_data(userData):
      return userData.lower()
  
  def validate_email_address(emailAddress):
      return "@" in emailAddress
  
  # Incorrect
  def processUserData(userData):
      return userData.lower()
  ```

- **Classes**: Use `PascalCase` (standard Python convention)
  ```python
  class DatabaseConnection:
      def __init__(self, connectionString):
          self.connectionString = connectionString
  ```

- **Constants**: Use `UPPER_SNAKE_CASE` (standard Python convention)
  ```python
  MAX_RETRY_ATTEMPTS = 3
  DEFAULT_API_TIMEOUT = 30
  ```

### Inline Comments for Problem-Solving Enhancement

**Always include inline comments that explain the logical flow and reasoning:**

```python
def analyze_network_traffic(packetData):
    # Parse raw packet data into structured format for analysis
    parsedPackets = []
    
    for rawPacket in packetData:
        # Extract header information to identify protocol type
        headerInfo = rawPacket[:20]  # First 20 bytes contain IP header
        
        # Determine if this is a suspicious connection attempt
        if headerInfo[9] == 6:  # TCP protocol identifier
            sourcePort = int.from_bytes(headerInfo[20:22], 'big')
            destinationPort = int.from_bytes(headerInfo[22:24], 'big')
            
            # Flag potential port scanning (sequential port access)
            if sourcePort > 1024 and destinationPort < 1024:
                # Log potential reconnaissance activity
                print(f"Suspicious connection: {sourcePort} -> {destinationPort}")
        
        parsedPackets.append(headerInfo)
    
    return parsedPackets
```

### Development Container Specific Guidelines

1. **Database Connections**: Reference the pre-configured PostgreSQL instance
   ```python
   # Use environment variables available in the container
   import os
   
   # Container provides these environment variables
   databaseUrl = os.getenv('DATABASE_URL', 'postgresql://postgres:postgres@db:5432/devdb')
   
   # Connect using the container's internal network
   def create_database_connection():
       # Establish connection to container's PostgreSQL service
       connection = psycopg2.connect(databaseUrl)
       return connection
   ```

2. **File Paths**: Use container-aware path handling
   ```python
   # Container workspace is mounted at /workspace
   workspaceRoot = "/workspace"
   dataDirectory = os.path.join(workspaceRoot, "data")
   
   # Handle volume-persisted data
   def save_analysis_results(analysisData, fileName):
       # Save to persistent volume so data survives container restarts
       persistentPath = os.path.join("/workspace/data", fileName)
       
       # Ensure directory exists in container filesystem
       os.makedirs(os.path.dirname(persistentPath), exist_ok=True)
       
       with open(persistentPath, 'w') as outputFile:
           json.dump(analysisData, outputFile)
   ```

3. **Container Resource Awareness**:
   ```python
   import multiprocessing
   
   def optimize_for_container():
       # Container may have limited CPU cores allocated
       availableCores = multiprocessing.cpu_count()
       
       # Use conservative threading to avoid container resource limits
       optimalThreads = min(availableCores, 4)  # Cap at 4 threads
       
       return optimalThreads
   ```

## Security & Cybersecurity Context

When working with security tools in this container:

```python
def scan_network_vulnerabilities(targetRange):
    # Container has nmap pre-installed for network reconnaissance
    import nmap
    
    # Initialize scanner with container's network interface
    networkScanner = nmap.PortScanner()
    
    # Scan from within container's network context
    scanResults = networkScanner.scan(targetRange, '1-1000')
    
    # Process results with awareness of container networking
    for hostAddress in scanResults['scan']:
        hostInfo = scanResults['scan'][hostAddress]
        
        # Check for commonly exploited services
        if 'tcp' in hostInfo:
            for portNumber, portInfo in hostInfo['tcp'].items():
                # Flag potentially vulnerable services
                if portInfo['state'] == 'open':
                    serviceName = portInfo.get('name', 'unknown')
                    
                    # Log findings with container timestamp
                    print(f"Open service found: {serviceName} on {hostAddress}:{portNumber}")
    
    return scanResults
```

## Data Science & Analysis Guidelines

For Jupyter notebooks and data analysis:

```python
def process_large_dataset(dataFilePath):
    # Container has pandas/numpy optimized for data processing
    import pandas as pd
    import numpy as np
    
    # Load data with memory optimization for container limits
    dataFrame = pd.read_csv(dataFilePath, chunksize=10000)  # Process in chunks
    
    processedResults = []
    
    for dataChunk in dataFrame:
        # Apply analysis logic to each chunk to manage memory
        chunkMean = dataChunk.select_dtypes(include=[np.number]).mean()
        
        # Store intermediate results to avoid memory buildup
        processedResults.append(chunkMean)
        
        # Clear variables to free container memory
        del dataChunk
    
    # Combine results after processing all chunks
    finalResults = pd.concat(processedResults, ignore_index=True)
    
    return finalResults
```

## Error Handling with Container Context

```python
def handle_container_specific_errors():
    try:
        # Attempt database connection using container service
        connectionString = "postgresql://postgres:postgres@db:5432/devdb"
        databaseConnection = psycopg2.connect(connectionString)
        
    except psycopg2.OperationalError as dbError:
        # Container-specific database troubleshooting
        print("Database connection failed - check if db service is running in compose")
        print("Try: docker-compose ps to verify service status")
        raise
        
    except FileNotFoundError as fileError:
        # Handle volume mounting issues
        print("File not found - check if workspace volume is properly mounted")
        print("Container workspace should be at /workspace")
        raise
        
    except PermissionError as permError:
        # Handle container filesystem permissions
        print("Permission denied - check container user permissions")
        print("Files should be owned by vscode user in container")
        raise
```

## Testing in Container Environment

```python
import unittest

class ContainerAwareTestCase(unittest.TestCase):
    def setUp(self):
        # Set up test environment aware of container context
        self.testDataPath = "/workspace/test_data"
        self.databaseTestUrl = "postgresql://postgres:postgres@db:5432/testdb"
        
        # Ensure test directories exist in container
        os.makedirs(self.testDataPath, exist_ok=True)
    
    def test_database_connectivity(self):
        # Test container's database service connectivity
        try:
            testConnection = psycopg2.connect(self.databaseTestUrl)
            testConnection.close()
            self.assertTrue(True, "Database connection successful")
        except Exception as connectionError:
            self.fail(f"Container database connection failed: {connectionError}")
    
    def tearDown(self):
        # Clean up test artifacts in container filesystem
        if os.path.exists(self.testDataPath):
            import shutil
            shutil.rmtree(self.testDataPath)
```

## Performance Optimization for Container

```python
def optimize_container_performance():
    # Monitor container resource usage
    import psutil
    
    # Check available memory in container
    availableMemory = psutil.virtual_memory().available
    memoryThreshold = availableMemory * 0.8  # Use max 80% of available memory
    
    # Adjust processing based on container resources
    if availableMemory < 1024 * 1024 * 1024:  # Less than 1GB
        # Use memory-conservative processing
        chunkSize = 1000
    else:
        # Normal processing for well-resourced containers
        chunkSize = 10000
    
    return chunkSize
```

## Integration with Container Tools

```python
def use_container_tools():
    # Leverage pre-installed container tools
    
    # Use container's git for version control
    def commit_analysis_results(commitMessage):
        import subprocess
        
        # Git is pre-configured in container
        subprocess.run(['git', 'add', '.'], cwd='/workspace')
        subprocess.run(['git', 'commit', '-m', commitMessage], cwd='/workspace')
    
    # Use container's security tools
    def run_security_scan(targetFile):
        # Container has security analysis tools pre-installed
        import subprocess
        
        # Run static analysis using container tools
        scanResult = subprocess.run(['bandit', targetFile], 
                                  capture_output=True, text=True)
        
        return scanResult.stdout
```

Remember: This development environment is optimized for rapid prototyping and analysis while maintaining security best practices. Always consider container resource limits and leverage the pre-installed tools for maximum efficiency. 